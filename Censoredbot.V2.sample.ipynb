{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abbf05de-0814-425c-8b6d-c2d120b17f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4b8ae7-21d1-4c7f-a1c6-d8411d4537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import discord\n",
    "from discord.ext import commands\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584f3bb3-32fb-4900-acd3-3a24c2de82a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.3750 - loss: 0.7018\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.6250 - loss: 1.8973\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.7500 - loss: 0.6056\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.5000 - loss: 0.6794\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8750 - loss: 0.5609\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8750 - loss: 0.4557\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.7500 - loss: 0.4365\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8750 - loss: 0.3142\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8750 - loss: 0.2948\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#ê²€ì—´ ë°ì´í„°(0)\n",
    "censored_images = [\"ê²€ì—´1.jpg\", \"ê²€ì—´2.png\", \"ê²€ì—´3.png\"]\n",
    "\n",
    "#í—ˆìš©ë²”ìœ„(1)\n",
    "valid_images = [\"í—ˆìš©ë²”ìœ„1.png\", \"í—ˆìš©ë²”ìœ„2.png\", \"í—ˆìš©ë²”ìœ„3.png\", \"í—ˆìš©ë²”ìœ„4.png\", \"í—ˆìš©ë²”ìœ„5.jpg\"]\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def load_and_process_images(image_list, label):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_path in image_list:\n",
    "        img = load_img(img_path, target_size=(128, 128))  # ì´ë¯¸ì§€ ë¡œë“œ ë° í¬ê¸° ì¡°ì •\n",
    "        img_array = img_to_array(img) / 255.0  # ì •ê·œí™” (0~1 ë²”ìœ„)\n",
    "        data.append(img_array)\n",
    "        labels.append(label)  # í´ë˜ìŠ¤ ë¼ë²¨ ì¶”ê°€\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "censored_data, censored_labels = load_and_process_images(censored_images, 0)  # ê²€ì—´(0)\n",
    "valid_data, valid_labels = load_and_process_images(valid_images, 1)  # í—ˆìš©(1)\n",
    "\n",
    "# ë°ì´í„° í•©ì¹˜ê¸°\n",
    "X = np.concatenate((censored_data, valid_data), axis=0)\n",
    "y = np.concatenate((censored_labels, valid_labels), axis=0)\n",
    "\n",
    "# ë°ì´í„° ì„ê¸°\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# CNN ëª¨ë¸ ì •ì˜ (ì´ì§„ ë¶„ë¥˜)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # ì´ì§„ ë¶„ë¥˜\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ë°ì´í„° ì¦ê°• ì ìš©(ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ ëª©ì ) \n",
    "datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True)\n",
    "train_generator = datagen.flow(X, y, batch_size=32)\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model.fit(train_generator, epochs=10)\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "model.save(\"image_filter_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4ed11-27b8-4361-96b3-b620e6805d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot ready!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "âœ… ì •ìƒ ì´ë¯¸ì§€: midtermexamê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "âŒ ìœ í•´ ì´ë¯¸ì§€ ì‚­ì œë¨: midtermexamê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "# ë””ìŠ¤ì½”ë“œ ë´‡ í† í° (ì—¬ê¸°ì— ìì‹ ì˜ ë´‡ í† í° ì…ë ¥)\n",
    "TOKEN = 'your_token'\n",
    "CHANNEL_ID = \"your_channel_ID\"\n",
    "\n",
    "# ì €ì¥ëœ CNN ëª¨ë¸ ë¡œë“œ\n",
    "model = tf.keras.models.load_model(\"image_filter_model.h5\")\n",
    "\n",
    "# ë””ìŠ¤ì½”ë“œ ë´‡ ì„¤ì •\n",
    "bot = commands.Bot(command_prefix=\"!\", intents=discord.Intents.all())\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (CNN ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)\n",
    "def preprocess_image(image_bytes):\n",
    "    image = Image.open(io.BytesIO(image_bytes)).resize((128, 128))\n",
    "    image = np.array(image) / 255.0  # ì •ê·œí™”\n",
    "    image = np.expand_dims(image, axis=0)  # ëª¨ë¸ ì…ë ¥ ì°¨ì› ë§ì¶”ê¸°\n",
    "    return image\n",
    "\n",
    "@bot.event\n",
    "async def on_ready():\n",
    "     print(\"Bot ready!\")\n",
    "\n",
    "@bot.event\n",
    "async def on_message(message):\n",
    "    if message.author == bot.user:\n",
    "        return\n",
    "\n",
    "    for attachment in message.attachments:\n",
    "        if attachment.content_type.startswith('image'):\n",
    "            image_bytes = await attachment.read()\n",
    "            image = preprocess_image(image_bytes)\n",
    "\n",
    "            prediction = model.predict(image)\n",
    "            predicted_label = int(prediction[0][0] > 0.5)  # 0: ê²€ì—´ë¨, 1: ì •ìƒ\n",
    "\n",
    "            if predicted_label == 0:  # ìœ í•´ ì´ë¯¸ì§€ ê°ì§€\n",
    "                await message.delete()\n",
    "                 await asyncio.sleep(2)\n",
    "                await message.channel.send(f\"ğŸš¨ {message.author.mention}, ìœ í•´í•œ ì´ë¯¸ì§€ê°€ ê°ì§€ë˜ì–´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(f\"âŒ ìœ í•´ ì´ë¯¸ì§€ ì‚­ì œë¨: {message.author}ê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€\")\n",
    "\n",
    "            else:\n",
    "                print(f\"âœ… ì •ìƒ ì´ë¯¸ì§€: {message.author}ê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€\")\n",
    "                 await asyncio.sleep(2)\n",
    "\n",
    "\n",
    "async def start_bot():\n",
    "    await bot.start(TOKEN)\n",
    "\n",
    "asyncio.run(start_bot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0477f-82d9-40ef-82d2-be11bb9043e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
