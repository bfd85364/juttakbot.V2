{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abbf05de-0814-425c-8b6d-c2d120b17f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b4b8ae7-21d1-4c7f-a1c6-d8411d4537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import discord\n",
    "from discord.ext import commands\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584f3bb3-32fb-4900-acd3-3a24c2de82a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.3750 - loss: 0.7018\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.6250 - loss: 1.8973\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.7500 - loss: 0.6056\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.5000 - loss: 0.6794\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8750 - loss: 0.5609\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8750 - loss: 0.4557\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.7500 - loss: 0.4365\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8750 - loss: 0.3142\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8750 - loss: 0.2948\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#검열 데이터(0)\n",
    "censored_images = [\"검열1.jpg\", \"검열2.png\", \"검열3.png\"]\n",
    "\n",
    "#허용범위(1)\n",
    "valid_images = [\"허용범위1.png\", \"허용범위2.png\", \"허용범위3.png\", \"허용범위4.png\", \"허용범위5.jpg\"]\n",
    "\n",
    "# 이미지 로드 및 전처리 함수\n",
    "def load_and_process_images(image_list, label):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_path in image_list:\n",
    "        img = load_img(img_path, target_size=(128, 128))  # 이미지 로드 및 크기 조정\n",
    "        img_array = img_to_array(img) / 255.0  # 정규화 (0~1 범위)\n",
    "        data.append(img_array)\n",
    "        labels.append(label)  # 클래스 라벨 추가\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# 데이터 로드\n",
    "censored_data, censored_labels = load_and_process_images(censored_images, 0)  # 검열(0)\n",
    "valid_data, valid_labels = load_and_process_images(valid_images, 1)  # 허용(1)\n",
    "\n",
    "# 데이터 합치기\n",
    "X = np.concatenate((censored_data, valid_data), axis=0)\n",
    "y = np.concatenate((censored_labels, valid_labels), axis=0)\n",
    "\n",
    "# 데이터 섞기\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# CNN 모델 정의 (이진 분류)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # 이진 분류\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 데이터 증강 적용(데이터 불균형 해소 목적) \n",
    "datagen = ImageDataGenerator(rotation_range=20, horizontal_flip=True)\n",
    "train_generator = datagen.flow(X, y, batch_size=32)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_generator, epochs=10)\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"image_filter_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4ed11-27b8-4361-96b3-b620e6805d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot ready!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "✅ 정상 이미지: midtermexam가 업로드한 이미지\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "❌ 유해 이미지 삭제됨: midtermexam가 업로드한 이미지\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "# 디스코드 봇 토큰 (여기에 자신의 봇 토큰 입력)\n",
    "TOKEN = 'your_token'\n",
    "CHANNEL_ID = \"your_channel_ID\"\n",
    "\n",
    "# 저장된 CNN 모델 로드\n",
    "model = tf.keras.models.load_model(\"image_filter_model.h5\")\n",
    "\n",
    "# 디스코드 봇 설정\n",
    "bot = commands.Bot(command_prefix=\"!\", intents=discord.Intents.all())\n",
    "\n",
    "# 이미지 전처리 함수 (CNN 입력 형식으로 변환)\n",
    "def preprocess_image(image_bytes):\n",
    "    image = Image.open(io.BytesIO(image_bytes)).resize((128, 128))\n",
    "    image = np.array(image) / 255.0  # 정규화\n",
    "    image = np.expand_dims(image, axis=0)  # 모델 입력 차원 맞추기\n",
    "    return image\n",
    "\n",
    "@bot.event\n",
    "async def on_ready():\n",
    "     print(\"Bot ready!\")\n",
    "\n",
    "@bot.event\n",
    "async def on_message(message):\n",
    "    if message.author == bot.user:\n",
    "        return\n",
    "\n",
    "    for attachment in message.attachments:\n",
    "        if attachment.content_type.startswith('image'):\n",
    "            image_bytes = await attachment.read()\n",
    "            image = preprocess_image(image_bytes)\n",
    "\n",
    "            prediction = model.predict(image)\n",
    "            predicted_label = int(prediction[0][0] > 0.5)  # 0: 검열됨, 1: 정상\n",
    "\n",
    "            if predicted_label == 0:  # 유해 이미지 감지\n",
    "                await message.delete()\n",
    "                 await asyncio.sleep(2)\n",
    "                await message.channel.send(f\"🚨 {message.author.mention}, 유해한 이미지가 감지되어 삭제되었습니다.\")\n",
    "                print(f\"❌ 유해 이미지 삭제됨: {message.author}가 업로드한 이미지\")\n",
    "\n",
    "            else:\n",
    "                print(f\"✅ 정상 이미지: {message.author}가 업로드한 이미지\")\n",
    "                 await asyncio.sleep(2)\n",
    "\n",
    "\n",
    "async def start_bot():\n",
    "    await bot.start(TOKEN)\n",
    "\n",
    "asyncio.run(start_bot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0477f-82d9-40ef-82d2-be11bb9043e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
